{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364aaec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meu1404/miniforge/envs/rapids-ml/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-21 08:05:55.200246: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /home/meu1404/projects/test/Deep_learning_tutorial\n"
     ]
    }
   ],
   "source": [
    "import os, io, re, zipfile, pathlib, random, pickle\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "BASE_DIR = pathlib.Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "ARTIFACTS_DIR = BASE_DIR / \"artifacts\"\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "EMBED_DIM = 100 \n",
    "VOCAB_SIZE = 20000\n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "\n",
    "print('BASE_DIR:', BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f8d7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.20.0\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print('TF:', tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('GPUs:', gpus)\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception as e:\n",
    "        print('memory_growth error:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5c4e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"stanfordnlp/imdb\")\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da05c225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, np.int32(12500), np.int32(12500))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = [r[\"text\"] for r in ds[\"train\"]]\n",
    "train_labels = np.array([int(r[\"label\"]) for r in ds[\"train\"]], dtype=\"int32\")\n",
    "\n",
    "test_texts  = [r[\"text\"] for r in ds[\"test\"]]\n",
    "test_labels = np.array([int(r[\"label\"]) for r in ds[\"test\"]], dtype=\"int32\")\n",
    "\n",
    "len(train_texts), len(test_texts), sum(train_labels), sum(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd3e877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i rented i am curious-yellow from my video store because of all the controversy that surrounded it when it was first released in 1967. i also heard that at first it was seized by u.s. customs if it ever tried to enter this country, therefore being a fan of films considered controversial i really had\n"
     ]
    }
   ],
   "source": [
    "def basic_clean(s: str) -> str:\n",
    "    s = s.replace(\"<br />\", \" \")\n",
    "    s = re.sub(r\"<.*?>\", \" \", s)\n",
    "    s = re.sub(r\"[^A-Za-z0-9'.,!?;:()\\- ]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "train_clean = [basic_clean(t) for t in train_texts]\n",
    "test_clean  = [basic_clean(t) for t in test_texts]\n",
    "\n",
    "print(train_clean[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50af3edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 200), (25000, 200), 20000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_clean)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(train_clean)\n",
    "x_test  = tokenizer.texts_to_sequences(test_clean)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "x_test  = pad_sequences(x_test,  maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(VOCAB_SIZE, len(word_index) + 1)\n",
    "\n",
    "with open(ARTIFACTS_DIR / \"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "x_train.shape, x_test.shape, nb_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4362f93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe file: /home/meu1404/projects/test/Deep_learning_tutorial/data/glove.6B/glove.6B.100d.txt exists: True\n"
     ]
    }
   ],
   "source": [
    "GLOVE_URL = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "glove_zip_path = keras.utils.get_file(origin=GLOVE_URL, fname=\"glove.6B.zip\", cache_dir=str(DATA_DIR), cache_subdir=\".\")\n",
    "glove_root = pathlib.Path(glove_zip_path).parent / \"glove.6B\"\n",
    "glove_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "zip_path = pathlib.Path(glove_zip_path)\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    for name in z.namelist():\n",
    "        if name.startswith(\"glove.6B.\") and name.endswith(\".txt\"):\n",
    "            target = glove_root / pathlib.Path(name).name\n",
    "            if not target.exists():\n",
    "                z.extract(name, path=glove_root)\n",
    "\n",
    "glove_txt = glove_root / f\"glove.6B.{EMBED_DIM}d.txt\"\n",
    "print(\"GloVe file:\", glove_txt, \"exists:\", glove_txt.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b9e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400,000 tokens\n",
      "Init embeddings: matched 19,154/20,000 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20000, 100), 20000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_glove_matrix(word_index: dict, glove_txt_path: pathlib.Path, vocab_size: int, emb_dim: int):\n",
    "    embeddings_index = {}\n",
    "    with io.open(glove_txt_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = \" \".join(values[:-emb_dim]) if len(values) > emb_dim+1 else values[0]\n",
    "            coefs = np.asarray(values[-emb_dim:], dtype=\"float32\")\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"GloVe loaded: {len(embeddings_index):,} tokens\")\n",
    "\n",
    "    nb_words = min(vocab_size, len(word_index) + 1)\n",
    "    embedding_matrix = np.random.normal(scale=0.6, size=(nb_words, emb_dim)).astype(\"float32\")\n",
    "    found = 0\n",
    "    for w, i in word_index.items():\n",
    "        if i >= nb_words: \n",
    "            continue\n",
    "        vec = embeddings_index.get(w)\n",
    "        if vec is not None and len(vec) == emb_dim:\n",
    "            embedding_matrix[i] = vec\n",
    "            found += 1\n",
    "    print(f\"Init embeddings: matched {found:,}/{nb_words:,} tokens\")\n",
    "    return embedding_matrix, nb_words\n",
    "\n",
    "emb_matrix, nb_words = build_glove_matrix(word_index, glove_txt, nb_words, EMBED_DIM)\n",
    "emb_matrix.shape, nb_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1f5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758441983.789393    5160 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1756 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/meu1404/miniforge/envs/rapids-ml/lib/python3.12/site-packages/keras/src/trainers/trainer.py:212: UserWarning: Model doesn't support `jit_compile=True`. Proceeding with `jit_compile=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">176,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m2,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m176,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,193,153</span> (8.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,193,153\u001b[0m (8.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,193,153</span> (8.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,193,153\u001b[0m (8.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model_gru(nb_words, emb_matrix, max_len, emb_dim, units=128, lr=LR):\n",
    "    inp = keras.layers.Input(shape=(max_len,), name=\"input_ids\")\n",
    "    x = keras.layers.Embedding(\n",
    "        nb_words, emb_dim, weights=[emb_matrix], trainable=True, name=\"embedding\"\n",
    "    )(inp)\n",
    "    x = keras.layers.SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(units,\n",
    "                         dropout=0.2,\n",
    "                         recurrent_dropout=0.0,\n",
    "                         reset_after=True,\n",
    "                         return_sequences=False)\n",
    "    )(x)\n",
    "\n",
    "    x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inp, out)\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    try:\n",
    "        model.compile(\n",
    "            optimizer=opt,\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"), keras.metrics.AUC(name=\"auc\")],\n",
    "            jit_compile=True\n",
    "        )\n",
    "    except TypeError:\n",
    "        model.compile(\n",
    "            optimizer=opt,\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"), keras.metrics.AUC(name=\"auc\")]\n",
    "        )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model_gru(nb_words, emb_matrix, MAX_LEN, EMBED_DIM, units=128)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6570ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 08:06:27.599782: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 54ms/step - acc: 0.6185 - auc: 0.6627 - loss: 0.6366 - val_acc: 0.8328 - val_auc: 0.0000e+00 - val_loss: 0.4294 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - acc: 0.8453 - auc: 0.9166 - loss: 0.3664 - val_acc: 0.8904 - val_auc: 0.0000e+00 - val_loss: 0.2911 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - acc: 0.8996 - auc: 0.9565 - loss: 0.2645 - val_acc: 0.7936 - val_auc: 0.0000e+00 - val_loss: 0.5344 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - acc: 0.9252 - auc: 0.9749 - loss: 0.1981 - val_acc: 0.7632 - val_auc: 0.0000e+00 - val_loss: 0.6922 - learning_rate: 5.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - acc: 0.9402 - auc: 0.9822 - loss: 0.1653 - val_acc: 0.7808 - val_auc: 0.0000e+00 - val_loss: 0.6901 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8450e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - acc: 0.8951 - auc: 0.9547 - loss: 0.2697 - val_acc: 0.8320 - val_auc: 0.0000e+00 - val_loss: 0.4079 - learning_rate: 1.2500e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - acc: 0.8972 - auc: 0.9567 - loss: 0.2634 - val_acc: 0.8288 - val_auc: 0.0000e+00 - val_loss: 0.4009 - learning_rate: 1.2500e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - acc: 0.9009 - auc: 0.9598 - loss: 0.2546 - val_acc: 0.8200 - val_auc: 0.0000e+00 - val_loss: 0.4280 - learning_rate: 1.2500e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - acc: 0.9066 - auc: 0.9618 - loss: 0.2470 - val_acc: 0.8060 - val_auc: 0.0000e+00 - val_loss: 0.4518 - learning_rate: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "split = int(0.9 * len(x_train))\n",
    "x_tr, y_tr = x_train[:split], train_labels[:split]\n",
    "x_val, y_val = x_train[split:], train_labels[split:]\n",
    "\n",
    "ds_tr  = tf.data.Dataset.from_tensor_slices((x_tr,  y_tr)).shuffle(25000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(ds_tr, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615dcd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu văn cần đánh giá: \"Style over substance; empty and self-indulgent.\"\n",
      "Kết quả: NEGATIVE | score=0.159\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "def basic_clean(s: str) -> str:\n",
    "    s = s.replace(\"<br />\", \" \")\n",
    "    s = re.sub(r\"<.*?>\", \" \", s)\n",
    "    s = re.sub(r\"[^A-Za-z0-9'.,!?;:()\\-\\s]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "def predict_sentiment(text: str, model=model, tokenizer=tokenizer, max_len=MAX_LEN):\n",
    "    t = basic_clean(text)\n",
    "    seq = tokenizer.texts_to_sequences([t])\n",
    "    seq = pad_sequences(seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "    prob = float(model.predict(seq, verbose=0)[0][0])\n",
    "    label = \"positive\" if prob >= 0.5 else \"negative\"\n",
    "    return prob, label\n",
    "\n",
    "s = input(\"Nhập câu đánh giá phim: \")\n",
    "prob, lab = predict_sentiment(s)\n",
    "print(f\"Câu văn cần đánh giá: \\\"{s}\\\"\")\n",
    "print(f\"Kết quả: {lab.upper()} | score={prob:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-ml (CUDA12.5)",
   "language": "python",
   "name": "rapids-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
