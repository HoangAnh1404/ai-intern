{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "364aaec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /home/meu1404/projects/test/Deep_learning_tutorial\n"
     ]
    }
   ],
   "source": [
    "import os, io, re, zipfile, pathlib, random, pickle\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "BASE_DIR = pathlib.Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "ARTIFACTS_DIR = BASE_DIR / \"artifacts\"\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "EMBED_DIM = 100 \n",
    "VOCAB_SIZE = 20000\n",
    "MAX_LEN = 300\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "\n",
    "print('BASE_DIR:', BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63f8d7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.20.0\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "memory_growth error: Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "print('TF:', tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('GPUs:', gpus)\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception as e:\n",
    "        print('memory_growth error:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c5c4e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"stanfordnlp/imdb\")\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da05c225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, np.int32(12500), np.int32(12500))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = [r[\"text\"] for r in ds[\"train\"]]\n",
    "train_labels = np.array([int(r[\"label\"]) for r in ds[\"train\"]], dtype=\"int32\")\n",
    "\n",
    "test_texts  = [r[\"text\"] for r in ds[\"test\"]]\n",
    "test_labels = np.array([int(r[\"label\"]) for r in ds[\"test\"]], dtype=\"int32\")\n",
    "\n",
    "len(train_texts), len(test_texts), sum(train_labels), sum(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd3e877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i rented i am curious-yellow from my video store because of all the controversy that surrounded it when it was first released in 1967. i also heard that at first it was seized by u.s. customs if it ever tried to enter this country, therefore being a fan of films considered controversial i really had\n"
     ]
    }
   ],
   "source": [
    "def basic_clean(s: str) -> str:\n",
    "    s = s.replace(\"<br />\", \" \")\n",
    "    s = re.sub(r\"<.*?>\", \" \", s)\n",
    "    s = re.sub(r\"[^A-Za-z0-9'.,!?;:()\\- ]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "train_clean = [basic_clean(t) for t in train_texts]\n",
    "test_clean  = [basic_clean(t) for t in test_texts]\n",
    "\n",
    "print(train_clean[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50af3edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 300), (25000, 300), 20000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_clean)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(train_clean)\n",
    "x_test  = tokenizer.texts_to_sequences(test_clean)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "x_test  = pad_sequences(x_test,  maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(VOCAB_SIZE, len(word_index) + 1)\n",
    "\n",
    "with open(ARTIFACTS_DIR / \"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "x_train.shape, x_test.shape, nb_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4362f93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe file: /home/meu1404/projects/test/Deep_learning_tutorial/data/glove.6B/glove.6B.100d.txt exists: True\n"
     ]
    }
   ],
   "source": [
    "GLOVE_URL = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "glove_zip_path = keras.utils.get_file(origin=GLOVE_URL, fname=\"glove.6B.zip\", cache_dir=str(DATA_DIR), cache_subdir=\".\")\n",
    "glove_root = pathlib.Path(glove_zip_path).parent / \"glove.6B\"\n",
    "glove_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "zip_path = pathlib.Path(glove_zip_path)\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    for name in z.namelist():\n",
    "        if name.startswith(\"glove.6B.\") and name.endswith(\".txt\"):\n",
    "            target = glove_root / pathlib.Path(name).name\n",
    "            if not target.exists():\n",
    "                z.extract(name, path=glove_root)\n",
    "\n",
    "glove_txt = glove_root / f\"glove.6B.{EMBED_DIM}d.txt\"\n",
    "print(\"GloVe file:\", glove_txt, \"exists:\", glove_txt.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51b9e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400,000 tokens\n",
      "Init embeddings: matched 19,154/20,000 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20000, 100), 20000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_glove_matrix(word_index: dict, glove_txt_path: pathlib.Path, vocab_size: int, emb_dim: int):\n",
    "    embeddings_index = {}\n",
    "    with io.open(glove_txt_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = \" \".join(values[:-emb_dim]) if len(values) > emb_dim+1 else values[0]\n",
    "            coefs = np.asarray(values[-emb_dim:], dtype=\"float32\")\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"GloVe loaded: {len(embeddings_index):,} tokens\")\n",
    "\n",
    "    nb_words = min(vocab_size, len(word_index) + 1)\n",
    "    embedding_matrix = np.random.normal(scale=0.6, size=(nb_words, emb_dim)).astype(\"float32\")\n",
    "    found = 0\n",
    "    for w, i in word_index.items():\n",
    "        if i >= nb_words: \n",
    "            continue\n",
    "        vec = embeddings_index.get(w)\n",
    "        if vec is not None and len(vec) == emb_dim:\n",
    "            embedding_matrix[i] = vec\n",
    "            found += 1\n",
    "    print(f\"Init embeddings: matched {found:,}/{nb_words:,} tokens\")\n",
    "    return embedding_matrix, nb_words\n",
    "\n",
    "emb_matrix, nb_words = build_glove_matrix(word_index, glove_txt, nb_words, EMBED_DIM)\n",
    "emb_matrix.shape, nb_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c1f5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meu1404/miniforge/envs/rapids-ml/lib/python3.12/site-packages/keras/src/trainers/trainer.py:212: UserWarning: Model doesn't support `jit_compile=True`. Proceeding with `jit_compile=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m2,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m234,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,251,009</span> (8.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,251,009\u001b[0m (8.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,251,009</span> (8.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,251,009\u001b[0m (8.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(nb_words, emb_matrix, max_len, emb_dim):\n",
    "    inp = keras.layers.Input(shape=(max_len,), name=\"input_ids\")\n",
    "    x = keras.layers.Embedding(nb_words, emb_dim,\n",
    "                               weights=[emb_matrix],\n",
    "                               trainable=True, name=\"embedding\")(inp)\n",
    "    x = keras.layers.SpatialDropout1D(0.2)(x)\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.0, return_sequences=False)\n",
    "    )(x)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inp, out)\n",
    "    opt = keras.optimizers.Adam(learning_rate=LR)   # ❌ KHÔNG truyền jit_compile ở đây\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"), keras.metrics.AUC(name=\"auc\")],\n",
    "        jit_compile=True                              # ✅ jit_compile đặt ở đây\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(nb_words, emb_matrix, MAX_LEN, EMBED_DIM)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6570ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 11:35:43.988787: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 27000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - acc: 0.8631 - auc: 0.9286 - loss: 0.3383 - val_acc: 0.8672 - val_auc: 0.0000e+00 - val_loss: 0.3323 - learning_rate: 7.8125e-06\n",
      "Epoch 2/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 71ms/step - acc: 0.8600 - auc: 0.9276 - loss: 0.3405 - val_acc: 0.8640 - val_auc: 0.0000e+00 - val_loss: 0.3394 - learning_rate: 7.8125e-06\n",
      "Epoch 3/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - acc: 0.8638 - auc: 0.9295 - loss: 0.3363 - val_acc: 0.8664 - val_auc: 0.0000e+00 - val_loss: 0.3325 - learning_rate: 3.9063e-06\n",
      "Epoch 4/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - acc: 0.8568 - auc: 0.9288 - loss: 0.3380 - val_acc: 0.8656 - val_auc: 0.0000e+00 - val_loss: 0.3323 - learning_rate: 1.9531e-06\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8450e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 11:37:36.529685: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 27000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - acc: 0.8635 - auc: 0.9298 - loss: 0.3365 - val_acc: 0.8676 - val_auc: 0.0000e+00 - val_loss: 0.3297 - learning_rate: 1.0000e-06\n",
      "Epoch 2/10\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - acc: 0.8619 - auc: 0.9295 - loss: 0.3363 - val_acc: 0.8660 - val_auc: 0.0000e+00 - val_loss: 0.3336 - learning_rate: 1.0000e-06\n",
      "Epoch 3/10\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - acc: 0.8608 - auc: 0.9284 - loss: 0.3390 - val_acc: 0.8612 - val_auc: 0.0000e+00 - val_loss: 0.3420 - learning_rate: 1.0000e-06\n",
      "Epoch 4/10\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - acc: 0.8589 - auc: 0.9289 - loss: 0.3377 - val_acc: 0.8624 - val_auc: 0.0000e+00 - val_loss: 0.3413 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "split = int(0.9 * len(x_train))\n",
    "x_tr, y_tr = x_train[:split], train_labels[:split]\n",
    "x_val, y_val = x_train[split:], train_labels[split:]\n",
    "\n",
    "ds_tr  = tf.data.Dataset.from_tensor_slices((x_tr,  y_tr)).shuffle(25000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(ds_tr, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "615dcd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu văn cần đánh giá: The cinematography is stunning; every frame looks like a painting.\n",
      "Kết quả: POSITIVE | score=0.696\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "def basic_clean(s: str) -> str:\n",
    "    s = s.replace(\"<br />\", \" \")\n",
    "    s = re.sub(r\"<.*?>\", \" \", s)\n",
    "    s = re.sub(r\"[^A-Za-z0-9'.,!?;:()\\-\\s]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "def predict_sentiment(text: str, model=model, tokenizer=tokenizer, max_len=MAX_LEN):\n",
    "    t = basic_clean(text)\n",
    "    seq = tokenizer.texts_to_sequences([t])\n",
    "    seq = pad_sequences(seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "    prob = float(model.predict(seq, verbose=0)[0][0])\n",
    "    label = \"positive\" if prob >= 0.5 else \"negative\"\n",
    "    return prob, label\n",
    "\n",
    "# Nhập từ bàn phím\n",
    "s = input(\"Nhập câu đánh giá phim: \")\n",
    "prob, lab = predict_sentiment(s)\n",
    "print(f\"Câu văn cần đánh giá: {s}\")\n",
    "print(f\"Kết quả: {lab.upper()} | score={prob:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-ml (CUDA12.5)",
   "language": "python",
   "name": "rapids-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
